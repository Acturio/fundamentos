# Tipos de estudio y experimentos

```{r setup, include=FALSE, message=FALSE}
library(tidyverse)
source("R/funciones_auxiliares.R")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning=FALSE)
comma <- function(x) format(x, digits = 2, big.mark = ",")
theme_set(theme_minimal())
```

## De datos y poblaciones {-}

Los datos no son el fin último de un estudio. Son el mecanismo que podemos utilizar para poder contestar
preguntas acerca de la población que no vemos. Pensemos en la encuesta realizada en el Reino Unido 
sobre parejas sexuales del sexo opuesto 
que una persona en el rango de edad de 35-44 años declara tener. Este estudio está tomado de @spiegelhalter2019art. 
Los datos están reportados en la encuesta Natsal-3 que puede encontrarse en [C.H. Mercer et al., ‘Changes in Sexual Attitudes and Lifestyles in Britain through the Life Course and Over Time: Findings from the National Surveys of Sexual Attitudes and Lifestyles (Natsal)’, 2013](https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(13)62035-8/fulltext).

Estos datos corresponden a un total de 796 hombres y 1,193 mujeres encuestadas, y están ponderados por el diseño 
estratificado de la encuesta.

```{r, echo  = FALSE}
library(ggplot2)
nastal <-read.csv("data/nastal.csv", header=TRUE)
nastal <- nastal %>%
  rename(NumParejas = NumPartners, ConteoH = MenCount, ConteoM = WomenCount)
sample_n(nastal, 10)
```

Como en los ejemplos anteriores, podemos calcular un resumen rápido para hombres:

```{r, echo  = FALSE}
nastal %>% 
  summarise(Datos = rep(NumParejas,ConteoH)) %>%
  pull(Datos) %>% 
  summary()
```

así como un resumen rápido para las mujeres encuestadas:

```{r, echo  = FALSE}
nastal %>% 
  summarise(Datos = rep(NumParejas,ConteoM)) %>%
  pull(Datos) %>% 
  summary()
```

Un gráfico sencillo nos ayudará a ilustrar la distirbución de las respuestas por género:
```{r, fig.align ='center', out.width='95%', fig.height = 3, fig.width = 5}
nastal %>% 
  select(NumParejas, ConteoH, ConteoM) %>% 
  rename(Hombres = ConteoH, Mujeres = ConteoM) %>% 
  gather('Hombres', 'Mujeres', key='Género', value = 'Conteo') %>% 
  ggplot(aes(x = NumParejas)) + 
    geom_bar(aes(y = Conteo, fill = Género), stat = 'identity', position = 'dodge') + 
    scale_x_continuous(breaks = c(0,5,10,15,20,25,30,35,40,45,50), limits=c(0,50)) + 
    scale_colour_brewer(palette = "Set1") +
    labs(x="Número reportado de parejas sexuales del genero opuesto")
```
¿Cómo podemos generalizar a la población después de haber observado dichos resultados en la encuesta? 
Podemos seguir el siguiente tren de pensamiento:  
```{block, type = 'comentario'}
1. El *número registrado* de parejas sexuales de los participantes nos habla acerca de ...  
2. El *número real* de parejas sexuales en nuestra *muestra*, lo que nos habla acerca de ...   
3. El número de parejas en la *población de estudio*, lo que nos habla acerca de ...   
4. El número de parejas sexuales en el Reino Unido, lo cual es la *población objetivo*.
```

Los puntos más débiles en la generalización son los siguientes:  
```{block, type = 'comentario'}
1. ¿Podemos asumir que los encuestados responderán de manear exacta la pregunta? Observa los *picos* en el eje horizontal.  
2. ¿Podemos esperar que los encuestados hayan sido escogidos de manera aleatoria de aquellos que son elegibles?  Posiblemente, pero ¿podemos esperar los que aceptaron la encuesta son representativos?  
3. ¿Podemos asegurar que la muestra de encuestados representa la población adulta del país?  
```

## Hacia el trabajo como **Juez** {-}

Este papel lo tomamos cuando queremos describir algo más allá de los datos que observamos. 
Para esto necesitamos realizar *inferencia inductiva.* El peligro es que la inducción es un proceso 
generalmente lleno con incertidumbre, pues implica tomar instancias muy particulares para poder emitir 
juicios generales. En cambio, el trabajo *deductivo* considera una secuencia de 
implicaciones lógicas que nos llevan de generalidades a casos particulares. 

Posiblemente, a lo largo de su preparación, o en cursos anteriores de estadística, han 
considerado los casos cuando los datos que observamos son seleccionados al azar de la población
objetivo. Sin embargo, esto raramente sucede en la vida real, y es por esto que es necesario considerar 
el proceso desde la captura de datos hasta la población objetivo. Por ejemplo, la población de adultos
en Reino Unido con una vida sexual activa. 

En general nos interesa que nuestros datos sean:   
* Confiables, es decir, con poca variabilidad y que sea un evento repetible.   
* Válidos, en el sentido que en verdad se esté midiendo lo que queremos medir, y que no haya sesgos.   

Por otro lado, para poder asegurar que la muestra sea adecuada y nos permita observar 
de manera fiable la población necesitamos que el estudio tenga *validez interna.* La forma
más efectiva de reducir el sesgo es por medio de **muestreo aleatorio.**

Por último, nos interesa que haya *validez externa* en los datos, lo cual significa que en verdad 
nuestras unidades de observación representen la poblacion de interés.

#### Población {-}

Hasta ahora hemos hablado de muestras de datos. Es un caso muy común en las encuestas. Sin embargo, 
también es posible econtrar casos dónde tengamos acceso a todo conjunto de datos de interés. Ejemplos
de esto son los casos de donde los casos se registran de manera continua como estudios de compras en línea o 
históricos transaccionales en un banco. 

Aún en estas situaciones hay que considerar evaluar si en verdad todo lo que nos interesa se registra. 
Por ejemplo, las carpetas de investigación de crímenes en la ciudad de México: ¿contienen el reporte de 
todos los posibles crímenes en la ciudad? 

#### Distribuciones {-} 

Hasta ahora hemos mencionado el concepto de distribución como el patrón que presentan los datos 
(valores centrales, dispersión, rango, etc.). A esta distribución le llamamos **distribución muestral** 
o **empírica**. En general, esperamos que nuestros datos tengan las mismas características (estadísticas) 
que la población de donde provienen. Por ejemplo, cuando un fenómeno es generado por pequeñas influencias 
hablamos de la distribución Normal o Gaussiana a nivel teórico. El siguiente ejemplo es tomado de libro de 
@spiegelhalter2019art, y es sobre el peso de los bebés al nacer. 


```{r, echo = FALSE, fig.align = 'center', out.width = '95%', message = FALSE}
weights=c(1500, 2000, 2500, 3000, 3500, 4000, 4500,5000)
mids=weights+250
n=c(5+48+308+1130, 12679, 124209, 442891, 389275, 108886, 14936,1345) # numbers in each bin
N=sum(n)  # total number of babies
area=N*500  # number * binwidth = total area of histogram
lbw   = sum(n[1:2])   # number with low birth weight (less than 2500)
lbw.percent=100*lbw/N  # % low birth weight
# 1.3%
#calculate mean and sd of population
# could use sheppard's correction
birth.mean=sum(n*mids/N)
birth.sd=sqrt( sum(n*(mids-birth.mean)^2)/N)
# per cent less than 2500 from normal approximation
lbw.est = 100 * pnorm(2500,birth.mean, birth.sd)
# 1.7%, good approxmation
#25th and 75th percentiles of population
# qnorm(0.25, birth.mean,birth.sd)
# qnorm(0.75, birth.mean,birth.sd)
# percentile of baby weighing 2910
xw = 2910  
# pnorm(xw, birth.mean,birth.sd)
par(mfrow=c(2,2))
# setup plot ranges noting max of normal density is at mean
xrange <- c(1500,5500)
yrange <- range( c(n, area*dnorm(birth.mean, birth.mean, birth.sd), 0))
scale=0.6
par(mar=c(5,0,1,0)+0.1)
# (a) empirical distribution and fitted normal
plot(xrange, yrange, type = "n", xlab = "", ylab = "",
     bty="n",axes=F,main="(a) Distribution of birthweights", cex=scale)
axis(1,cex=scale) 
# draw bars using rect and density using curve
rect(weights, 0, weights + 500, n, col = "lightblue")
curve(area*dnorm(x, birth.mean, birth.sd), min(xrange), max(xrange), add = TRUE, 
      lwd=3, col="blue")
lines(c(xw,xw),yrange,col="red",lwd=2)
# (b)   plot with sds  
plot(xrange, yrange, type = "n", xlab = "", ylab = "",
     bty="n",axes=F,,main="(b) Mean +/- 1, 2, 3 SDs" )
axis(1)
curve(area*dnorm(x, birth.mean, birth.sd), min(xrange), max(xrange), add = TRUE, lwd=3, col="blue")
I=-3:3
x1=birth.mean+I*birth.sd
y1=area*dnorm(x1,birth.mean, birth.sd)
label=c("-3 SDs", "-2 SDs", "-1 SD", "mean", "+1 SD","+2 SDs", "+3 SDs")
bit=10000
xx=250
shift=c(-xx,-xx,-xx,0,xx,xx,xx)
for(i in 1:7){
  lines(c(x1[i],x1[i]), c(0,y1[i]),lwd=2)
  text(x1[i]+shift[i],y1[i]+bit,label[i],cex=0.75)
}
lines(c(xw,xw),yrange,col="red",lwd=2)
# (c)  Percentiles  
plot(xrange, yrange, type = "n", xlab = "Birthweight (gms)", ylab = "",
     bty="n",axes=F,,main="(c) Percentiles" )
axis(1)
curve(area*dnorm(x, birth.mean, birth.sd), min(xrange), max(xrange), add = TRUE,
      lwd=3, col="blue")
I=c(1,5,25,50,75,95,99)
x1=qnorm(I/100, birth.mean,birth.sd)
y1=area*dnorm(x1,birth.mean, birth.sd)
label=c("1%", "5%", "25%", "50%","75%","95%","99%")
bit=5000
for(i in 1:7){
  lines(c(x1[i],x1[i]), c(0,y1[i]),lwd=2,lty=2)
  text(x1[i],-bit,label[i],cex=0.6)
}
lines(c(xw,xw),yrange,col="red",lwd=2)
# (d)  Low birth weight  
plot(xrange, yrange, type = "n", xlab = "Birthweight (gms)", ylab = "",
     bty="n",axes=F,,main="(d) Low birth weight" )
axis(1)
curve(area*dnorm(x, birth.mean, birth.sd), min(xrange), max(xrange), add = TRUE,
      lwd=3, col="blue")
x1=seq(1500,2500,10)
y1=area*dnorm(x1,birth.mean, birth.sd)
polygon(c(x1,x1[101:1]),c(rep(0,101), y1[101:1]),col="lightblue")
lines(c(xw,xw),yrange,col="red",lwd=2)
x1=seq(1500,xw,10)
nx=length(x1)
y1=area*dnorm(x1,birth.mean, birth.sd)
polygon(c(x1,x1[nx:1]),c(rep(0,nx), y1[nx:1]),col="red",density=10)
text(2000,70000,"Proportion\n below\n 2500 gms\n = 1.7%",cex=0.75)
text(3400,70000,"Proportion\n below\n 2910 gms\n = 11%",cex=0.75)
```

Entonces, podemos pensar en la población como un conjunto de individuos que provee
la distirbución de probabilidad de una observación aleatoria. Esto será muy útil 
cuando lleguemos al momento de hacer *inferencia estadística.* Cuyo objetivo es 
poder hacer afirmaciones sobre las características como media, moda, o dispersión que
en general no sabemos de antemano. 

En los casos donde no hay muestreo (análisis de crímenes en una ciudad, o estudios 
censales) la diferencia entre población y muestra no existe. Sin embargo, la noción
de población es valiosa. Pero, ¿cómo definimos una población?


```{block, type='comentario'}
Existen tres tipos de población de la cual podemos extraer una muestra de forma aleatoria:  
  - Población *literal.* Cuando podemos identificar a un grupo de dónde extraer muestras aleatorias.  
  - Población *virtual.* Cuando tomamos observaciones del ambiente, por ejemplo tomar mediciones de la calidad de aire. Los datos generados por en este escenario se denominan **muestras observacionales.**  
  - Población *metafórica.* Cuando no hay grupo de individuos mas grande. Pero aún asi podemos pensar como si los datos provienen de un espacio imaginario de posibilidades. Los datos geberados en este escenario se denominan **muestras naturales.**  
```

## Trabajando como **Juez** {-}

Ahora nos enfocaremos en interpretar resultados estadísticos. Para esto 
consideraremos el contexto de  **dos muestras**. Es una práctica común en el análisis
estadístico pues permite contrastar el efecto de un diseño o prueba. Ejemplos
de esto los vemos al medir la tasa de captura en diseño de páginas *web*, pruebas
de una nueva medicina, o simple contraste entre dos poblaciones con
características distintas.



Una *respuesta* a una pregunta de interés
viene acomapañada de una *medida de incertidumbre*, la cual se basa en una
*modelo de probabilidad*. Hay veces en el que el modelo de probabilidad está
bien justificado, pues hay un *mecanismo aleatorio* detrás ---pensemos en el
lanzamiento de una moneda. En otras ocasiones el modelo de probabilidad es un
*artefacto* matemático que asemeja la realidad y permite aplicar
*modelos estadísticos*.

Para entender y comunicar las conclusiones de un modelo hay que estar
conscientes del mecanismo aleatorio que se utilizó, por ejemplo, en la selección
de unidades muestrales, o del grupo al que pertenecen.

Hay dos formas de hacer inferencia. La **inferencia causal** y la **inferencia a
poblaciones**. Saber los mecanismos que generaron los datos nos permite saber
qué tipo de inferencia es más adecuada para el estudio en cuestión.

### Inferencia Causal {-}

En un **experimento aleatorizado** la investigadora asume el control de
asignación de cada unidad experimental a los distintos grupos de estudio por
medio de un mecanismo aleatorio, por ejemplo, una moneda. 

En un **estudio observacional** la asignación a los grupos se encuentra fuera del 
control de la investigadora. 

Es natural cuestionar si por medio de análisis estadísticos podemos concluir
relaciones causales. La respuesta es: 

```{block, type='comentario'}
Las relaciones de causa y efecto se pueden inferir sólo si se utiliza un estudio aleatorizado, 
pero no por medio de estudios observacionales. 
```

El componente aleatorio asegura que las unidades observacionales con diferentes
características se mezclen, y cualquier evidencia de dicha relación se muestra
en el estudio. Aún asi, no hay certeza absoluta de la presencia de la
relación causal. Dicha incertidumbre es la que usualemente se pretende inculuir
en el modelo a través de técnicas estadísticas.

En un estudio observacional es imposible concluir una relación causal por medio
de un análisis estadístico. La analista no puede asegurar la ausencia de algún
factor de confusión (*confounding variable*) que sea responsable de distorsionar
las conclusiones.

```{block, type='comentario'}
Un factor de confusión está asociado tanto a la pertenencia de un grupo de estudio 
como al resultado del estudio mismo. La presencia de un factor de confusión no permite
relacionar de manera directa la consecuencia con la pertenencia al grupo. 
```

#### El valor de estudios observacionales {-}

Incluso aunque no podamos establecer relaciones causa-efecto, los estudios observacionales 
poseen valor en un estudio formal. Las ventajas se pueden resumir en: 

1. El objetivo del estudio. A veces establecer relaciones de causa-efecto no es el objetivo
2. Establecer la relacion causa-efecto se puede hacer por medio de otras rutas. 
3. Datos observacionales pueden sugerir nuevas direcciones de investigación a través de *evidencia*.

### Inferencia de poblaciones {-}

La situación es bastante clara. Inferir características de una poblacion **sólo** se puede realizar por 
medio de muestreo aleatorio,  no de otra forma.  

Seleccionar de manera aleatoria significa que cualquier conjunto de tamaño $N$ que escojamos tiene 
la misma probabilidad de ser escogido que cualquier otro conjunto del mismo tamaño. 


<!-- ### Experimentos y datos observacionales {-} -->


